# -*- coding: utf-8 -*-
"""BigramCount_Input(3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tp157f0sFJliElAqPhrs5ypUXPSdxDbz
"""

import re

# Mapper function: Tokenizes the text into words and emits word bigrams
def mapper(text):
    words = re.findall(r"[\w']+", text)  # Tokenize the text into words using regular expressions
    for i in range(len(words) - 1):
        bigram = f"{words[i]},{words[i + 1]}"  # Create a bigram pair
        yield (bigram, 1)  # Emit the bigram as a key and 1 as the value

# Reducer function: Aggregates counts for each bigram
def reducer(bigram, counts):
    total_count = sum(counts)  # Sum up the counts for the same bigram
    yield (bigram, total_count)  # Emit the bigram and its total count

# Read input data from a file
input_file = "BigramCount_Input(3).txt"
input_data = []

with open(input_file, "r") as file:
    for line in file:
        input_data.append(line)

# Map and Reduce
bigram_counts = {}
for line in input_data:
    for bigram, count in mapper(line):
        if bigram not in bigram_counts:
            bigram_counts[bigram] = []
        bigram_counts[bigram].append(count)

result = {}
for bigram, counts in bigram_counts.items():
    for bigram, count in reducer(bigram, counts):
        result[bigram] = count

# Print the output
for bigram, count in result.items():
    print(f'"{bigram}" {count}')